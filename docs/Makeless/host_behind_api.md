#LLM #API

#### Question:
Hiding the large language models (LLM) behind an API for inference is a common practice in industry. But why?

#### Answer:
1. Prohibit direct access to the trained LLM, which is the key to business.
2. Control cost on the centralised inference, and optimise on it.
3. Limit model behaviours on generation, banning replies by moderation.
4. Support interactions with downstream tasks, including search, coding, scientific calculation, etc.
5. Allow better version control and price distribution for different models.

### Conclusion:
> The LLM research community is going close-sourced.
> The users are getting used to the standard interface.
> This is the only practical way to allow adoption of powerful LLM in industry.