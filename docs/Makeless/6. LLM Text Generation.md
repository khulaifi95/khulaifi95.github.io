#LLM #Generation


![[Screenshot from 2023-04-08 23-52-19.png]]

> Reference: https://arxiv.org/pdf/2210.14140.pdf

### 1. Introduction
LLMs are able to generate the next token conditioned on the previous sequence.

Given that greedy generation of each token tends to return gibberish, heuristics are needed for better generation. 


