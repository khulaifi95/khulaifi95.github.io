#LLM #Business

#### Question:
The (distributed) inference task is expensive compared to hosting a sparse index search engine or optimized specialist models , how does the business model support the up-scaling?

#### Answer:
1. LLM often provides human-preferred AI-generated results.
2. LLM allows instructions supporting many categories of NLP tasks.
3. LLM behind API can be amortized to be much cheaper ($0.002/10k token).
4. Scaling up models promises scaled-up marginal value in competition.
5. You only need one 'YES'.

### Conclusion:
> The competition is driven into a new era, where commercialising LLM is more opportune.